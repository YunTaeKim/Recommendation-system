{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book's title: Building Recommendation Engines\n",
    "\n",
    "\n",
    "## 1. 협업 필터링 추천 시스템\n",
    "> *기본적인 형태의 추천 시스템으로 사용자들의 선호도를 이용해서 선택 가능한 많은 집합들로부터 아이템들을 필터링한다. 두 명의 사용자가*\n",
    "> *과거에 동일한 관심사를 공유하고 있었다면 미래에도 유사한 취향을 갖고 있을 것이라는 기본적인 가정을 하고 있다.*\n",
    " \n",
    "### 1.1 사용자 기반 협업 필터링\n",
    "\n",
    "#### (1) 구축 방법\n",
    " 1. 유사한 선호도를 가진 사용자를 발견함.\n",
    " 2. 활성 사용자는 아직 등급을 매기지 않은 아이템에 대해 유사한 사용자가 제공한 등급을 참고해 활성 사용자에게 새로운 아이템을 추천함.\n",
    " \n",
    "#### (2) 단점\n",
    " - 사용자 등급들이 매우 부족한 경우 성능 저하가 발생함.\n",
    " - 데이터 규모가 매우 큰 경우 모든 사용자에 대한 유사도 값을 구하기 위한 계산 비용이 매우 큼.\n",
    " - 사용자 프로필 또는 사용자 입력이 빠르게 변할 경우 유사도 값을 다시 계산해야 하며, 계산 비용이 높아짐.\n",
    "  \n",
    "### 1.2 아이템 기반 협업 필터링\n",
    "\n",
    "#### (1) 구축 방법\n",
    " 1. 아이템 선호도를 기반으로 아이템 유사도를 계산함.\n",
    " 2. 활성 사용자가 아직 평가하지 않은 가장 유사한 아이템을 찾은 다음, 해당 아이템들을 추천함.\n",
    " \n",
    "#### (2) 장점\n",
    " - 구현하기 쉬움.\n",
    " - 추천 생성 시에 제품의 콘텐츠 정보 또는 사용자 프로필 정보는 필요하지 않음.\n",
    " - 사용자에게 깜짝 놀랄 만한 새로운 아이템을 추천함.\n",
    " \n",
    "#### (3) 단점\n",
    " - 유사도 계산을 위해 모든 사용자, 제품, 그리고 등급 전보가 메모리에 로드되기 때문에 계산 비용이 높다.\n",
    " - 사용자에 대한 정보가 전혀 없는 경우에는 적합하지 않음. (콜드 스타트 문제)\n",
    " - 데이터가 거의 없는 경우 성능이 저하됨.\n",
    " - 사용자 또는 제품에 대한 콘텐츠 정보가 없기 떄문에 등급 정보만으로는 정확한 추천을 생성할 수 없음. \n",
    " \n",
    "### 1.3 구축 시 고려사항\n",
    " - 사용자 사이의 유사도는 어떻게 계산하는가?\n",
    " - 아이템 사이의 유사도는 어떻게 계산하는가?\n",
    " - 추천하는 방법은 무엇인가?\n",
    " - 정보가 없는 새로운 아이템과 새로운 사용자들인 경우 어떻게 대처하는가?\n",
    " \n",
    "\n",
    "## 2. 콘텐츠 기반 추천 시스템\n",
    "> *아이템 속성과 해당 아이템 속성에 대한 사용자 선호도를 사용하는 추천 방법으로, 추천 모델을 구축하기 위해 아이템의 콘텐츠 정보를* \n",
    "> *사용한다. 콘텐츠 추천 시스템은 활성 사용자를 위한 추천 사항을 생성하는 데 일반적으로 사용자 프로필 생성 단계,*\n",
    "> *아이템 프로필 생성 단계, 모델 구축 단계를 포함한다. 콘텐츠 기반 추천 시스템은 아이템과 사용자 프로필의 콘텐츠 또는 특징을*\n",
    "> *이용해서 사용자에게 아이템을 추천한다. 즉, **시스템은 사용자가 과거에 좋아했던 것과 유사한 아이템들을 추천한다.** *\n",
    "> *아이템의 유사도는 다른 비교 아이템들과 관련된 특징을 기반으로 계산하며 사용자의 과거 선호도와 비교한다.*\n",
    "\n",
    "### 2.1 구축 시 고려사항\n",
    " - 제품의 콘텐츠 또는 특징들을 선택하는 방법은 무엇인가?\n",
    " - 해당 제품 콘텐츠와 유사한 선호도로 사용자 프로필을 생성하는 방법은 무엇인가?\n",
    " - 아이템들의 특징을 기반으로 아이템 사이의 유사도를 생성하는 방법은 무엇인가?\n",
    " - 사용자 프로필을 생성하고 계속적으로 업데이트하는 방법은 무엇인가?\n",
    " \n",
    "### 2.2 구축 방법\n",
    "1. 제품에 대한 콘텐츠 정보를 생성.\n",
    "2. 사용자 프로필과 제품 특징에 관련된 선호도를 생성.\n",
    "3. 추천을 생성하고 사용자가 좋아할 만한 아이템 리스트를 예측함.\n",
    "\n",
    "#### (1) 아이템 프로필 생성\n",
    " - 제품의 콘텐츠는 웹사이트와 관련도니 후기, 태그, 또는 텍스트 속성을 포함한다.\n",
    " - 아이템 프로필 생성 단계에서 관련 특징과 제품에 관련된 상대적 중요도를 추출해야 한다.\n",
    " - 아이템과 연관된 특징의 상대적 중요도를 계산하는 데 TF-IDF를 사용한다.\n",
    " \n",
    "#### (2) 사용자 프로필 생성\n",
    " - 제품 콘텐츠와 매칭되는 사용자 프로필 또는 선호도 행렬을 생성한다.\n",
    " - 아이템 프로필과 비교할 수 있도록 생성하는 것이 유용하다.\n",
    " - 아이템 프로필과 동일하게 TF-IDF를 사용한다.\n",
    " \n",
    "#### (3) 유사도 측정\n",
    " - 주로 코사인 유사도를 활용한다.\n",
    " - 사용자 프로필과 아이템 프로필 간의 유사도를 측정하여 사용자 별로 각 영화에 대한 유사도를 측정하고 유사한 아이템을 추천한다.\n",
    " \n",
    "### 2.3 장점\n",
    " - 콘텐츠 기반 추천 시스템은 개인화 수준을 목표로 한다.\n",
    " - 협업 필터링 처럼 사용자 커뮤니티를 이용하기보다는 사용자 선호도만 이용해서 추천 생성을 한다.\n",
    " - 추천 사항을 처리 또는 생성하기 위해 추천 모델이 모든 데이터를 로드할 필요가 없어 실시간으로 적용 가능하다.\n",
    " - 등급 정보만 처리하는 것이 아니라 제품의 콘텐츠를 처리하기 때문에 협업 방식 대비 정확도가 높다.\n",
    " - 콜드 스타트 문제를 쉽게 해결할 수 있다.\n",
    " \n",
    "### 2.4 단점\n",
    " - 시스템이 더 개인화 됨에 따라 더 많은 사용자 정보가 시스템으로 유입되면 오직 사용자의 선호도에만 집중된 추천 사항을 생성한다.\n",
    " - 사용자 선호도와 관련 없는 새로운 제품은 사용자에게 소개하지 않는다.\n",
    " - 사용자는 자신의 주변에서 일어나는 일이나 최신 트렌드를 파악할 수  없게 된다.\n",
    "  \n",
    "## 3. 하이브리드 추천 시스템\n",
    "> *하이브리드 추천 시스템은 좀 더 견고한 시스템을 구축하기 위해 다양한 추천 시스템들을 결합한다.*\n",
    "> *다양한 추천 시스템을 걸합시킴으로써, 하나의 시스템이 지닌 단점을 다른 시스템의 장점으로 대체해 견고한 시스템을 구축한다.*\n",
    "\n",
    "### 3.1 구축 시 고려사항\n",
    " - 비즈니스 솔루션을 달성하기 위해선느 어떤 추천 기술과 결합해야 하는가?\n",
    " - 더 나은 예측을 위해 다양한 기술과 그 결과를 어떻게 결함해야 하는가?\n",
    " \n",
    "### 3.2 구축 방법\n",
    " - 가중 방식\n",
    " - 혼합 방식\n",
    " - 전환 방식\n",
    " - 캐스케이드 방식\n",
    " - 특징 조합 방식\n",
    " - 특징 증가\n",
    " - 메타 레벨\n",
    " \n",
    "#### (1) 가중방식\n",
    " - 사용가능한 모든 추천 엔진의 추천 결과를 일반적으로 선형으로 조합한 것.\n",
    " - 초반에는 각 추천 엔진의 결과에 대해 동일한 가중치를 적용하며, 사용자가 추천 사항에 대한 반응을 평가해 점차 가중치를 조정한다.\n",
    " \n",
    "#### (2) 혼합 방식\n",
    " - 사용 가능한 몯느 추천 시스템의 결과를 혼합할 수 있는 곳에 적용 가능.\n",
    " - 일반적으로 데이터 희소성으로 인해 사용 가능한 모든 추천 시스템으로 부터 제품 점수를 얻는 것이 불가능한 곳에 사용됨.\n",
    " - 추천 사항들은 따로 생성되며 사용자에게 전달되기 전에 혼합됨.\n",
    " \n",
    "#### (3) 캐스케이드 방식\n",
    " - 협업 필터링을 이용해서 추천 사항을 생성.\n",
    " - 콘텐츠 기반 추천 기법이 적용된 후에 최종 추천 또는 순위 리스트가 결과로 제공됨.\n",
    " \n",
    "#### (4) 특징 조합 방식\n",
    " - 다양한 추천 시스템과 최종 추천 방식의 특징을 조합함.\n",
    " - 콘텐츠 기반 추천 시스템으로부터 얻은 사용자-아이템 선호도 특징과 사용자-아이템 등급 정보를 조합해 하이브리드 추천 시스템을 구축.\n",
    " \n",
    "### 3.3 장점\n",
    " - 콜드 스타트 문제와 데이터 희소성 같은 문제를 해결할 수 있음.\n",
    " - 개별 모델들 보다 훨씬 견고하고 확장 가능함.\n",
    " - 여러 방식들의 조합은 정확도를 향상시킴.\n",
    "\n",
    "## 4. 상황 인식 추천 시스템\n",
    "> *사용자 선호도는 현재 시각, 계절, 분위기, 장소, 시스템이 제공하는 옵션 등과 같은 상황에 따라 달라질 수 있기 때문에,*\n",
    "> *상황 인식 추천 시스템은 추천 시스템은 추천 항목을 계산하고 제안하기 전에 상황을 고려한다.*\n",
    "\n",
    "### 4.1 구축 시 고려사항\n",
    " - 추천 시스템에 사용할 상황은 어떻게 정의해야 하는가?\n",
    " - 비즈니스 솔루션을 달성하기 위해 어떤 기술을 이용해서 추천 시스템을 구축해야 하는가?\n",
    " - 제품과 관련해 사용자의 선호 상황을 어떻게 추출할 것인가?\n",
    " - 추천하기 위해 어떤 기술을 이용해서 사용자 프로필 선호도와 상황 선호도를 결합시켜야 하는가?\n",
    " \n",
    "### 4.2 상황의 정의\n",
    " - 일반적으로 상황은 사용자의 현재 상태를 나타낸다.\n",
    " - 지금까지는 추천을 2차원 문제, 사용자 선호도와 아이템으로 다뤘으나 상황을 새로운 차원으로 추가함으로써 3차원 문제로 만들 수 있다.\n",
    " - 추천 = 사용자 x 아이템 x 상황\n",
    " \n",
    "### 4.3 구축 방법\n",
    " 1. 사용자의 기호에 따라, 즉 콘텐츠 추천 기반으로 각 사용자에 대한 제품 추천 리스트를 생성한다.\n",
    " 2. 현재 상황에 한전된 추천 사항들을 **필터링**한다.\n",
    " \n",
    "#### (1)  사전 필터링 방식\n",
    " - 상황 정보를 사용자 프로필과 제품 콘텐츠에 적용한다.\n",
    " - 관련이 없는 특징들을 모두 걸러내고 남은 특징들을 기반으로 최종 개인화 추천을 생성한다.\n",
    " \n",
    "#### (2) 사후 필터링 방식\n",
    " - 먼저 사용자 프로필과 제품 카탈로그를 바탕으로 개인화 추천을 생성한 후, 상황정보를 적용해 현재 상황에 적합한 제품을 필터링한다.\n",
    " \n",
    "### 4.4 장점\n",
    " - 상황 인식 시스템은 사용자의 행동과 끊임없이 동기화하며 현재 상황에 맞는 추천을 생성하기 때문에 개인화 콘텐츠 기반 추천 시스템보다   \n",
    "   훨씬 앞선 시스템이다.\n",
    " - 이러한 시스템은 좀 더 많은 실시간 특성을 가진다.\n",
    " \n",
    "### 4.5 단점\n",
    " - 다른 개인화 추천 시스템과 마찬가지로 이러한 유형의 추천 시스템에서도 우연성이 없다.\n",
    " \n",
    "## 5. 모델 기반 추천 시스템\n",
    "> *기존의 접근법은 유사도 계산을 위해 전체 데이터를 환경에 로드해야하는 부담이 있고, 계산된 가중치가 머신러닝 방식처럼 자동으로 학습되지*\n",
    "> *않는다는 한계가 있다. 모델 기반 방식은 사용 가능한 과거 데이터를 이용해서 자동적으로 학습된 가중치로 모델을 생성해 특정 순서로 순위가*\n",
    "> *매겨진 최종 결과를 이용해서 추천한다.*\n",
    "\n",
    "### 5.1 확률적 접근법\n",
    " - 사용가능한 데이터로부터 사전 확률을 이용해 확률 모델을 생성한다.\n",
    " - 각 사용자의 제품에 대한 좋고 싫음의 확률을 계산해 추천 순위 리스트를 생성한다.\n",
    " \n",
    "### 5.2 머신러닝 접근법\n",
    " - 과거 사용자와 제품 데이터를 이용해 특징을 추출해 분류한 후 머신러닝 모델을 구축한다.\n",
    " - 로지스틱 회귀, KNN 분류, 결정트리, SVM, 클러스터링 등과 같은 다양한 머신러닝 기법을 사용할 수 있다.\n",
    "\n",
    "### 5.3 수학적 접근법\n",
    " - 제품에 대한 사용자의 등급 및 상호작용 정보를 단순한 행렬이라 가정한다.\n",
    " - 해당 행렬에 수학적 접근법을 적용해서 빠진 등급을 예측한다.\n",
    " - 행렬 인수 분해 모델, 특이값 분해 모델 등이 이용된다.\n",
    " \n",
    "### 5.4 장점\n",
    " - 모델 기반 추천은 이웃 기법과 같은 휴리스틱 기반 접근법보다 훨씬 정확하다.\n",
    " - 휴리스틱 기법에서는 제품 또는 제품 콘텐츠의 가중치가 고정적인 반면, 모델 기반 추천에서의 가중치는 자동 학습을 통해 정해진다.\n",
    " - 모델 기반 접근법은 데이터 구동 방식을 이용해서 보이지 않는 다양한 패턴들을 추출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/sureshgorakala/RecommenderSystems_R/master/movie_rating.csv'\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_ratings = data.pivot(index = 'title', columns = 'critic', values = 'rating')\n",
    "sim_users = movie_ratings.corr() # 사용자 간의 유사도 측정\n",
    "rating_critic = movie_ratings['Toby'] # 활성 사용자인 Toby의 평가 기록 추출\n",
    "titles_na_critic = list(rating_critic.index[rating_critic.isnull()]) # 평가하지 않은 영화 목록 추출\n",
    "\n",
    "ratings = data.loc[[t for t in data.index if data.loc[t, 'title'] in titles_na_critic]] # Toby가 평가하지 않은 영화를 본 평가자 추출\n",
    "ratings['similarity'] = list(sim_users['Toby'].loc[ratings['critic']]) # 각 평가자들과 Toby와의 유사도 부여\n",
    "ratings['sim_rating'] = ratings['similarity'] * ratings['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toby's predicted rating score for Just My Luck is 2.5310.\n",
      "Toby's predicted rating score for Lady in the Water is 2.8325.\n",
      "Toby's predicted rating score for The Night Listener is 3.3478.\n"
     ]
    }
   ],
   "source": [
    "for t in titles_na_critic:\n",
    "    dfm = ratings.loc[ratings['title'] == t]\n",
    "    score = dfm['sim_rating'].sum() / dfm['similarity'].sum()\n",
    "    \n",
    "    print(\"Toby's predicted rating score for %s is %.4f.\" % (t, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toby's rating mean is 3.1667.\n"
     ]
    }
   ],
   "source": [
    "print(\"Toby's rating mean is %s.\" % round(rating_critic.mean(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toby의 평균 평가 점수인 3.1667보다 높은 예상 평가 점수를 가진 The Night Listener 추천."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 movies\n"
     ]
    }
   ],
   "source": [
    "path = './data/ml-100k/u.data'\n",
    "df = pd.read_csv(path, sep = '\\t', header = None)\n",
    "df.columns = ['UserId', 'ItemId', 'Rating', 'Timestamp']\n",
    "\n",
    "n_users = df.UserId.unique().shape[0]\n",
    "n_items = df['ItemId'].unique().shape[0]\n",
    "\n",
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UBCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating matrix 생성\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1] - 1, row[2] - 1] = row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 6.30%\n"
     ]
    }
   ],
   "source": [
    "# sparsity 계산\n",
    "sparsity = float(len(ratings.nonzero()[0]))\n",
    "sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print('Sparsity: %4.2f%%' % (sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set shape: (631, 1682)\n",
      "test set shape: (312, 1682)\n"
     ]
    }
   ],
   "source": [
    "ratings_train, ratings_test = train_test_split(ratings, test_size = 0.33, random_state = 42)\n",
    "\n",
    "print('train set shape:', ratings_train.shape)\n",
    "print('test set shape:', ratings_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(631, 631)\n"
     ]
    }
   ],
   "source": [
    "# 사용자간의 거리 계산\n",
    "dist_out = 1 - cosine_distances(ratings_train)\n",
    "print(dist_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(631, 1682)\n"
     ]
    }
   ],
   "source": [
    "# 사용자 예측\n",
    "user_pred = dist_out.dot(ratings_train) / np.array([np.abs(dist_out).sum(axis = 1)]).T\n",
    "print(user_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE: 7.88219399155\n",
      "test MSE: 8.9224954317\n"
     ]
    }
   ],
   "source": [
    "def get_mse(pred, actual):\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)\n",
    "\n",
    "print('train MSE:', get_mse(user_pred, ratings_train))\n",
    "print('test MSE:', get_mse(user_pred, ratings_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-nearest neighbors\n",
    "k = 5\n",
    "\n",
    "neigh = NearestNeighbors(k, 'cosine')\n",
    "neigh.fit(ratings_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set prediction\n",
    "top_k_distances, top_k_users = neigh.kneighbors(ratings_train, return_distance = True)\n",
    "\n",
    "user_pred_k_tr = np.zeros(ratings_train.shape)\n",
    "for i in range(ratings_train.shape[0]):\n",
    "    user_pred_k_tr[i, :] = top_k_distances[i].T.dot(ratings_train[top_k_users][i]) / np.array(np.abs(top_k_distances[i].T).sum(axis = 0)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set prediction\n",
    "top_k_distances, top_k_users = neigh.kneighbors(ratings_test, return_distance = True)\n",
    "\n",
    "user_pred_k_te = np.zeros(ratings_test.shape)\n",
    "for i in range(ratings_test.shape[0]):\n",
    "    user_pred_k_te[i, :] = top_k_distances[i].T.dot(ratings_train[top_k_users][i]) / np.array(np.abs(top_k_distances[i].T).sum(axis = 0)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE: 8.19560651145\n",
      "test MSE: 8.12420902869\n"
     ]
    }
   ],
   "source": [
    "print('train MSE:', get_mse(user_pred_k_tr, ratings_train))\n",
    "print('test MSE:', get_mse(user_pred_k_te, ratings_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=1682, p=2,\n",
       "         radius='cosine')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = n_items\n",
    "neigh = NearestNeighbors(k, 'cosine')\n",
    "\n",
    "neigh.fit(ratings_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(631, 1682)\n"
     ]
    }
   ],
   "source": [
    "top_k_distances, top_k_items = neigh.kneighbors(ratings_train.T, return_distance = True)\n",
    "item_pred = ratings_train.dot(top_k_distances) / np.array([np.abs(top_k_distances).sum(axis = 1)])\n",
    "print(item_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
